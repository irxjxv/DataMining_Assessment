{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irxjxv/DataMining_Assessment/blob/main/Twitter_Depression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy8_zB3w3Jl0",
        "outputId": "eff0e417-f332-44bf-eb67-e6667901fe0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-p9-dwVvXDC"
      },
      "source": [
        "The goal of this project is to detect depression by using tweets. The training dataset comes from Twitter, gathered using Twint API. The testing dataset is from Kaggle, which is a collection of random tweets containing sentiment scores.\n",
        "\n",
        "The training dataset will be cleaned and preprocessed for exploratory data analysis and to build a model from it to use for our testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aiCA5EkZvU6Y",
        "outputId": "560cef43-3a19-45d0-e8f8-bb73c3a802f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting twint\n",
            "  Using cached twint-2.1.20-py3-none-any.whl\n",
            "Requirement already satisfied: aiohttp-socks in /usr/local/lib/python3.7/dist-packages (from twint) (0.4.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from twint) (3.8.1)\n",
            "Requirement already satisfied: aiodns in /usr/local/lib/python3.7/dist-packages (from twint) (3.0.0)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from twint) (1.17.0)\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.7/dist-packages (from twint) (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from twint) (1.3.5)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from twint) (0.1.11)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from twint) (4.6.3)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from twint) (2.1.7)\n",
            "Requirement already satisfied: googletransx in /usr/local/lib/python3.7/dist-packages (from twint) (2.4.2)\n",
            "Requirement already satisfied: pysocks in /usr/local/lib/python3.7/dist-packages (from twint) (1.7.1)\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.7/dist-packages (from twint) (8.0.0)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from aiodns->twint) (4.1.2)\n",
            "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pycares>=4.0.0->aiodns->twint) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns->twint) (2.21)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (3.10.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (2.0.12)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->twint) (4.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->twint) (2.10)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.7/dist-packages (from elasticsearch->twint) (8.0.1)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.7/dist-packages (from elastic-transport<9,>=8->elasticsearch->twint) (1.26.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elastic-transport<9,>=8->elasticsearch->twint) (2021.10.8)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy->twint) (1.52)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from googletransx->twint) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->twint) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->twint) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->twint) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->twint) (1.15.0)\n",
            "Installing collected packages: twint\n",
            "Successfully installed twint-2.1.20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "twint"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: twint 2.1.20\n",
            "Uninstalling twint-2.1.20:\n",
            "  Successfully uninstalled twint-2.1.20\n",
            "fatal: destination path 'twint' already exists and is not an empty directory.\n",
            "/content/twint/twint/twint\n",
            "Processing /content/twint/twint/twint\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: aiodns in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.6.3)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.1.7)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.6)\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (8.0.0)\n",
            "Requirement already satisfied: pysocks in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.7.1)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.3.5)\n",
            "Requirement already satisfied: aiohttp_socks<=0.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.4.1)\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.1.11)\n",
            "Requirement already satisfied: googletransx in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.4.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->-r requirements.txt (line 8)) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->-r requirements.txt (line 8)) (2018.9)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp_socks<=0.4.1->-r requirements.txt (line 9)) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (3.10.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (1.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->-r requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from aiodns->-r requirements.txt (line 2)) (4.1.2)\n",
            "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pycares>=4.0.0->aiodns->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns->-r requirements.txt (line 2)) (2.21)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r requirements.txt (line 6)) (8.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elastic-transport<9,>=8->elasticsearch->-r requirements.txt (line 6)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.7/dist-packages (from elastic-transport<9,>=8->elasticsearch->-r requirements.txt (line 6)) (1.26.8)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy->-r requirements.txt (line 11)) (1.52)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from googletransx->-r requirements.txt (line 13)) (2.27.1)\n",
            "Building wheels for collected packages: twint\n",
            "  Building wheel for twint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twint: filename=twint-2.1.21-py3-none-any.whl size=38871 sha256=7e4f97a7585413f86f4b2ca59fddc4f5661cec8118a8a08532c23a81f35f4449\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xs5l69e8/wheels/01/9e/ce/3e992f856c29a9479f09b9b988e98cb3a9cd6832b6566d9f25\n",
            "Successfully built twint\n",
            "Installing collected packages: twint\n",
            "Successfully installed twint-2.1.21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "twint"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neattext in /usr/local/lib/python3.7/dist-packages (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# install Twint for scraping data from Twitter\n",
        "\n",
        "import os\n",
        "\n",
        "!pip install twint\n",
        "!pip uninstall twint -y\n",
        "!git clone --depth=1 https://github.com/twintproject/twint.git\n",
        "%cd twint/\n",
        "!pip3 install . -r requirements.txt\n",
        "!pip install neattext\n",
        "\n",
        "import twint\n",
        "import pandas as pd\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "import time \n",
        "import datetime as dt\n",
        "from glob import glob\n",
        "import neattext.functions as neat_text\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YT5VS0WA2LHD"
      },
      "outputs": [],
      "source": [
        "# creating a function to get tweets using Twint\n",
        "\n",
        "def twint_search(search_term, since, until, save_path):\n",
        "    c = twint.Config()\n",
        "    c.Search = search_term\n",
        "    c.Lang = \"en\"\n",
        "    c.Since = since.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    c.Until = until.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    c.Hide_output = True\n",
        "    c.Store_csv = True\n",
        "    c.Output = save_path\n",
        "    twint.run.Search(c)\n",
        "    \n",
        "def twint_search_loop(search_term, start_date, end_date, save_dir):\n",
        "    try:\n",
        "        os.makedirs(os.path.join(os.getcwd(),save_dir,search_term))\n",
        "        print(f'Successfully created the directory {os.path.join(os.getcwd(),save_dir,search_term)}')\n",
        "    except FileExistsError:\n",
        "        print(f'Directory {os.path.join(os.getcwd(),save_dir,search_term)} already exists')\n",
        "    \n",
        "    date_range = pd.date_range(start_date, end_date)\n",
        "    \n",
        "    for single_date in date_range:\n",
        "        since = single_date\n",
        "        until = single_date + dt.timedelta(days=1)\n",
        "        save_path = os.path.join(save_dir, search_term, f'{single_date:%Y%m%d}.csv')\n",
        "        print(f\"Searching for tweets containing '{search_term}' from {single_date:%Y-%m-%d} and saving into {save_path}\")\n",
        "        twint_search(search_term, since, until, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ya8T0oO2WNQ"
      },
      "outputs": [],
      "source": [
        "# collect tweets with keywords such as depressed, suicide, etc. \n",
        "# tweets are gathered from 2022-2008 to achieve 100k data and saved to gdrive, creating a folder for each day with those tweets.\n",
        "\n",
        "search_term = \"depressed OR kill me OR suicide OR want to die OR lonely OR antidepressant OR hopeless OR sadness OR death OR worthless\"\n",
        "start_date = dt.datetime(2008, 1, 1)\n",
        "end_date = dt.datetime(2022, 2, 13)\n",
        "save_dir = 'drive/MyDrive/data/'\n",
        "\n",
        "# run search\n",
        "twint_search_loop(search_term, start_date, end_date, save_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "n9X25w4h4VTB"
      },
      "outputs": [],
      "source": [
        "# get the location of where the tweets are stored and combine them together in 1 csv file\n",
        "from glob import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "search_term = \"depressed OR kill me OR suicide OR want to die OR lonely OR antidepressant OR hopeless OR sadness OR death OR worthless\"\n",
        "save_dir = 'drive/MyDrive/data/'\n",
        "\n",
        "\n",
        "# csv_files = glob(os.path.join(save_dir, search_term, '*.csv'))\n",
        "csv_files = glob(os.path.join(save_dir, search_term, '*.csv'))\n",
        "\n",
        "# create DataFrames for each CSV file and combine into a single df\n",
        "dfs = [pd.read_csv(csv_file) for csv_file in csv_files]\n",
        "tweets_df = pd.concat(dfs).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8lOqG9F4msF"
      },
      "source": [
        "\n",
        "\n",
        "**The CSV file contains 101387 rows and 36 columns**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f49sEFzJ4jat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a7b8d1-21a3-43c1-bcb0-1c28fff1cefd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101387, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tweets_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW3ANzwY5BcK"
      },
      "outputs": [],
      "source": [
        "# These are the columns\n",
        "\n",
        "for col in tweets_df.columns:\n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGJf6ci15Isc"
      },
      "source": [
        "**First pre-processing step would be to remove unncessary column names**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "b-99sDId6LnH"
      },
      "outputs": [],
      "source": [
        "tweets_df.drop(['conversation_id',\n",
        "          'created_at',\n",
        "          'timezone',\n",
        "          'user_id',\n",
        "          'username',\n",
        "          'name',\n",
        "          'place',\n",
        "          'language',\n",
        "          'mentions',\n",
        "          'urls',\n",
        "          'photos',\n",
        "          'replies_count',\n",
        "          'retweets_count',\n",
        "          'likes_count',\n",
        "          'hashtags',\n",
        "          'cashtags',\n",
        "          'link',\n",
        "          'retweet',\n",
        "          'quote_url',\n",
        "          'video',\n",
        "          'thumbnail',\n",
        "          'near',\n",
        "          'geo',\n",
        "          'source',\n",
        "          'user_rt_id',\n",
        "          'user_rt',\n",
        "          'retweet_id',\n",
        "          'reply_to',\n",
        "          'retweet_date',\n",
        "          'translate',\n",
        "          'trans_src',\n",
        "          'trans_dest'], \n",
        "               axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KToLqWie6gDR"
      },
      "outputs": [],
      "source": [
        "# remaining columns will be id, date, time and tweet\n",
        "\n",
        "tweets_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_LT4ntL6owz"
      },
      "outputs": [],
      "source": [
        "# check if there are any missing rows\n",
        "\n",
        "tweets_df.isnull().any().any()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqKRlYHM6xb8"
      },
      "outputs": [],
      "source": [
        "tweets_df.info(null_counts=True) \n",
        "tweets_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um49wNBH7jlm"
      },
      "source": [
        "Cleaning up the date more by removing noise such as: \n",
        "\n",
        "\n",
        "*   hashtags\n",
        "*   @ or userhandles\n",
        "\n",
        "*   URLs\n",
        "*   multiple spaces\n",
        "\n",
        "*   numbers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "LQC54dfG7jDZ"
      },
      "outputs": [],
      "source": [
        "import neattext.functions as neat_text\n",
        "tweets_df['clean_tweet'] = tweets_df['tweet'].apply(neat_text.remove_hashtags)\n",
        "tweets_df['clean_tweet'] = tweets_df['clean_tweet'].apply(lambda x: neat_text.remove_userhandles(x))\n",
        "tweets_df['clean_tweet'] = tweets_df['clean_tweet'].apply(neat_text.remove_urls)\n",
        "tweets_df['clean_tweet'] = tweets_df['clean_tweet'].apply(neat_text.remove_multiple_spaces)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEjAGRXh9czI"
      },
      "source": [
        "Turning texts into lowercase to maintain consistency:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "U2UMCpdK9avc"
      },
      "outputs": [],
      "source": [
        "for columns in tweets_df.columns:\n",
        "    tweets_df['clean_tweet'] = tweets_df['clean_tweet'].str.lower() "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping duplicates after removing noise, we will just keep 1 of the duplicates from clean_tweet column. 90K tweets remain after deleting duplicates\n"
      ],
      "metadata": {
        "id": "xbpTZiytIjpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df.sort_values(\"clean_tweet\", inplace=True)\n",
        "unique_tweets_df = tweets_df.drop_duplicates(subset=[\"clean_tweet\"],keep = 'first')\n",
        "unique_tweets_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "OnIXyDMEI0Dj",
        "outputId": "086065cf-821c-4c10-e443-1829c71d520e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-272321c6-af12-40dc-b9f2-a99843523cb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63683</th>\n",
              "      <td>280071086589231104</td>\n",
              "      <td>2012-12-15</td>\n",
              "      <td>22:05:25</td>\n",
              "      <td>#i #hate #myself #and #want #to #die #suicide ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49786</th>\n",
              "      <td>1063552739160973312</td>\n",
              "      <td>2018-11-16</td>\n",
              "      <td>22:01:47</td>\n",
              "      <td>@ItsTimiDuhh !! Y'all don't want every girl to...</td>\n",
              "      <td>!! y'all don't want every girl to come to you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43817</th>\n",
              "      <td>953035217039712257</td>\n",
              "      <td>2018-01-15</td>\n",
              "      <td>22:44:36</td>\n",
              "      <td>@tonykill_ !!! i want to see tony kill live be...</td>\n",
              "      <td>!!! i want to see tony kill live before i die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18765</th>\n",
              "      <td>101795350565765120</td>\n",
              "      <td>2011-08-11</td>\n",
              "      <td>23:21:17</td>\n",
              "      <td>@libertyflintxx !!! like ever!! I'm scared I'm...</td>\n",
              "      <td>!!! like ever!! i'm scared i'm gonna fall off...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92853</th>\n",
              "      <td>588737680323645440</td>\n",
              "      <td>2015-04-16</td>\n",
              "      <td>16:16:15</td>\n",
              "      <td>@trashboatTsukki !!!!!!!!! SHET ARE YOU AIMING...</td>\n",
              "      <td>!!!!!!!!! shet are you aiming to kill me. bec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40938</th>\n",
              "      <td>900117904351535104</td>\n",
              "      <td>2017-08-22</td>\n",
              "      <td>22:10:06</td>\n",
              "      <td>🤤🤤 death by asphyxiation .. talk dirty to me R...</td>\n",
              "      <td>🤤🤤 death by asphyxiation .. talk dirty to me r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47950</th>\n",
              "      <td>1035301077971820544</td>\n",
              "      <td>2018-08-30</td>\n",
              "      <td>22:59:46</td>\n",
              "      <td>🥀 One of my weaknesses is my lack of a green t...</td>\n",
              "      <td>🥀 one of my weaknesses is my lack of a green t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73853</th>\n",
              "      <td>1254494584819810306</td>\n",
              "      <td>2020-04-26</td>\n",
              "      <td>19:36:31</td>\n",
              "      <td>🥺🥺 I’m too selfish to die for someone I love m...</td>\n",
              "      <td>🥺🥺 i’m too selfish to die for someone i love m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84944</th>\n",
              "      <td>1454950380379508738</td>\n",
              "      <td>2021-10-31</td>\n",
              "      <td>23:16:17</td>\n",
              "      <td>🦎♊🐉😈🌞🌚🌏🌍🌎🐕 saying I can make people depressed ...</td>\n",
              "      <td>🦎♊🐉😈🌞🌚🌏🌍🌎🐕 saying i can make people depressed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81588</th>\n",
              "      <td>1399135647366066179</td>\n",
              "      <td>2021-05-30</td>\n",
              "      <td>22:48:27</td>\n",
              "      <td>🧠 : stop being sad?  Me: why?  🧠 : because sad...</td>\n",
              "      <td>🧠 : stop being sad? me: why? 🧠 : because sadne...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90687 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-272321c6-af12-40dc-b9f2-a99843523cb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-272321c6-af12-40dc-b9f2-a99843523cb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-272321c6-af12-40dc-b9f2-a99843523cb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                        id  ...                                        clean_tweet\n",
              "63683   280071086589231104  ...                                                   \n",
              "49786  1063552739160973312  ...   !! y'all don't want every girl to come to you...\n",
              "43817   953035217039712257  ...      !!! i want to see tony kill live before i die\n",
              "18765   101795350565765120  ...   !!! like ever!! i'm scared i'm gonna fall off...\n",
              "92853   588737680323645440  ...   !!!!!!!!! shet are you aiming to kill me. bec...\n",
              "...                    ...  ...                                                ...\n",
              "40938   900117904351535104  ...  🤤🤤 death by asphyxiation .. talk dirty to me r...\n",
              "47950  1035301077971820544  ...  🥀 one of my weaknesses is my lack of a green t...\n",
              "73853  1254494584819810306  ...  🥺🥺 i’m too selfish to die for someone i love m...\n",
              "84944  1454950380379508738  ...  🦎♊🐉😈🌞🌚🌏🌍🌎🐕 saying i can make people depressed ...\n",
              "81588  1399135647366066179  ...  🧠 : stop being sad? me: why? 🧠 : because sadne...\n",
              "\n",
              "[90687 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TR0vtuh-6zL"
      },
      "source": [
        "Need to expand contractions for text standardisation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "41ADNYY_-N19"
      },
      "outputs": [],
      "source": [
        "# a list of contractions and their expanded form\n",
        "\n",
        "contractions = { \n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxVIlGZBAvi8",
        "outputId": "1e6eda54-f339-4153-85e8-f0bd7a3abcdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        id  ...                                        clean_tweet\n",
            "0       438460348073795584  ...  gogeta told morrigan to let him help her to ki...\n",
            "1       438459161240539136  ...   to beautiful to be depressed. they have no re...\n",
            "2       438458283452428289  ...  am alone, lonely, &amp; depressed because no o...\n",
            "3       438458006800330752  ...  “ \"hmm “ before i die i want to kill chris sma...\n",
            "4       438455764886097920  ...  “ before i die i want to kill chris smalling”o...\n",
            "...                    ...  ...                                                ...\n",
            "101382  759861573888258050  ...  \"kill me. please\" \"screw you\" damon begging to...\n",
            "101383  759859411397414912  ...   do you want me to die? cause like my parents ...\n",
            "101384  759855097786478592  ...   by trying to kill me in secret for my father'...\n",
            "101385  759853846457831424  ...  this isnt real right just kill me im going to ...\n",
            "101386  759853700416311296  ...  guy walking near me has the kill bill whistle ...\n",
            "\n",
            "[101387 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mapping = {k : v for k, v in contractions.items() }\n",
        "tweets_df['clean_tweet'] = tweets_df['clean_tweet'].replace(mapping, regex=True)\n",
        "print(tweets_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASwNFz-S5EBM",
        "outputId": "68810319-3e20-43e9-86be-1dbc31553cd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         gogeta told morrigan to let him help her to ki...\n",
              "1          to beautiful to be depressed. they have no re...\n",
              "2         am alone, lonely, &amp; depressed because no o...\n",
              "3         “ \"hmm “ before i die i want to kill chris sma...\n",
              "4         “ before i die i want to kill chris smalling”o...\n",
              "                                ...                        \n",
              "101382    \"kill me. please\" \"screw you\" damon begging to...\n",
              "101383     do you want me to die? cause like my parents ...\n",
              "101384     by trying to kill me in secret for my father'...\n",
              "101385    this isnt real right just kill me im going to ...\n",
              "101386    guy walking near me has the kill bill whistle ...\n",
              "Name: clean_tweet, Length: 101387, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "tweets_df['clean_tweet']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxB6OIgFAbMi",
        "outputId": "ed5d075c-6ba3-4a46-a9e5-46bcb68795e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                            448966550192930816\n",
              "date                                                  2014-03-26\n",
              "time                                                    23:35:41\n",
              "tweet          i’m depressed as fuck, i’m tired of  being lik...\n",
              "clean_tweet    i’m depressed as fuck, i’m tired of being like...\n",
              "Name: 647, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "tweets_df.iloc[647]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "8siRHUAeEMjU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2323
        },
        "outputId": "06808f9b-a772-4dc4-a7a0-c8a5c8a2a1c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7895552d-7c3a-44be-ab51-fdb57695cc64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43616</th>\n",
              "      <td>948669246434873344</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>21:35:48</td>\n",
              "      <td>@AngelOfEreri \"but you'll die first. i want to...</td>\n",
              "      <td>\"but you'll die first. i want to hear you apo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64374</th>\n",
              "      <td>289875944322236416</td>\n",
              "      <td>2013-01-11</td>\n",
              "      <td>23:26:25</td>\n",
              "      <td>http://t.co/gHUfc0Zg  \"Fat, Worthless, Whore,...</td>\n",
              "      <td>\"fat, worthless, whore, slut, immature, disgu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92355</th>\n",
              "      <td>577610776183074816</td>\n",
              "      <td>2015-03-16</td>\n",
              "      <td>23:21:55</td>\n",
              "      <td>@SC_Erwin_Smith \"Help me LEVI IS GOING TO KILL...</td>\n",
              "      <td>\"help me levi is going to kill me please hell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56915</th>\n",
              "      <td>1208174701425676295</td>\n",
              "      <td>2019-12-20</td>\n",
              "      <td>23:57:50</td>\n",
              "      <td>@djoats02 @Csillabubu \"hey im seriously strugg...</td>\n",
              "      <td>\"hey im seriously struggling and ive been con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94506</th>\n",
              "      <td>616693828259459073</td>\n",
              "      <td>2015-07-02</td>\n",
              "      <td>19:44:00</td>\n",
              "      <td>@Hatred_Reaper \"I dont die, no one will be abl...</td>\n",
              "      <td>\"i dont die, no one will be able to kill me o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50431</th>\n",
              "      <td>1081688653833912320</td>\n",
              "      <td>2019-01-05</td>\n",
              "      <td>23:07:26</td>\n",
              "      <td>⑤ oh i think id die right away.. like i dont t...</td>\n",
              "      <td>⑤ oh i think id die right away.. like i dont t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66389</th>\n",
              "      <td>332981710906073088</td>\n",
              "      <td>2013-05-10</td>\n",
              "      <td>22:13:21</td>\n",
              "      <td>♡ its funny how people always ignore me and do...</td>\n",
              "      <td>♡ its funny how people always ignore me and do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46252</th>\n",
              "      <td>1008088724570361856</td>\n",
              "      <td>2018-06-16</td>\n",
              "      <td>20:47:35</td>\n",
              "      <td>🆘🆘🆘 IAM A VERY HAPPY BOY BUT I WILL DIE IF SOM...</td>\n",
              "      <td>🆘🆘🆘 iam a very happy boy but i will die if som...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46255</th>\n",
              "      <td>1008083954942038016</td>\n",
              "      <td>2018-06-16</td>\n",
              "      <td>20:28:38</td>\n",
              "      <td>🆘🆘🆘I DONT WANT TO DIE BUT NOBODY WANTS ME. I A...</td>\n",
              "      <td>🆘🆘🆘i dont want to die but nobody wants me. i a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59035</th>\n",
              "      <td>209791079715844097</td>\n",
              "      <td>2012-06-04</td>\n",
              "      <td>23:37:45</td>\n",
              "      <td>😲 lol RT @Nay_zilla: Lol im not a killer but d...</td>\n",
              "      <td>😲 lol rt lol im not a killer but dont push me ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2505 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7895552d-7c3a-44be-ab51-fdb57695cc64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7895552d-7c3a-44be-ab51-fdb57695cc64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7895552d-7c3a-44be-ab51-fdb57695cc64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                        id  ...                                        clean_tweet\n",
              "43616   948669246434873344  ...   \"but you'll die first. i want to hear you apo...\n",
              "64374   289875944322236416  ...   \"fat, worthless, whore, slut, immature, disgu...\n",
              "92355   577610776183074816  ...   \"help me levi is going to kill me please hell...\n",
              "56915  1208174701425676295  ...   \"hey im seriously struggling and ive been con...\n",
              "94506   616693828259459073  ...   \"i dont die, no one will be able to kill me o...\n",
              "...                    ...  ...                                                ...\n",
              "50431  1081688653833912320  ...  ⑤ oh i think id die right away.. like i dont t...\n",
              "66389   332981710906073088  ...  ♡ its funny how people always ignore me and do...\n",
              "46252  1008088724570361856  ...  🆘🆘🆘 iam a very happy boy but i will die if som...\n",
              "46255  1008083954942038016  ...  🆘🆘🆘i dont want to die but nobody wants me. i a...\n",
              "59035   209791079715844097  ...  😲 lol rt lol im not a killer but dont push me ...\n",
              "\n",
              "[2505 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "unique_tweets_df[unique_tweets_df['clean_tweet'].str.contains(\"dont\")] "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df['clean_tweet'] = tweets_df['clean_tweet'].replace(\"’\", \"'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "6OF-XTodBR4a",
        "outputId": "aee93ed1-3221-4045-ae24-53b3824b395d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-40b68d49b358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_tweet'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"’\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tweets_df' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Twitter_Depression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18PwFPA-LB527ag7Ipe_xZziI7oeJU3Q_",
      "authorship_tag": "ABX9TyNGqqY7SPR0wJVGJcThRK4n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}